{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf5ef90",
   "metadata": {},
   "source": [
    "# Fonctions améliorations et erreurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6889d2",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcdbf6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = open(\"dictionnaire.txt\",\"r\",encoding = 'utf-8').read()\n",
    "text_string = open(\"texte.txt\",'r',encoding=\"utf-8\").read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c90ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_string,special_character,remplacement_string):\n",
    "    cleaned_text = text_string\n",
    "    for string in special_character:\n",
    "        cleaned_text = cleaned_text.replace(string,remplacement_string)\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return (cleaned_text)\n",
    "\n",
    "\n",
    "special_caracter=[',','.',\"'\",'\\n']\n",
    "remplacement =\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ffb1fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize (text_string,special_character,remplacement_string, clean = False ):\n",
    "    cleaned_text= text_string\n",
    "     \n",
    "         if clean:\n",
    "                cleaned_text= clean_text(text_string,special_caracter,remplacement)\n",
    "    text_tokens = cleaned_text.split(\" \")\n",
    "    return (text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b523b1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en', 'termes', 'généraux', 'la', 'scence', 'des', 'données', 'est', 'lextraction', 'de']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = tokenize(text_string,special_caracter,remplacement,True)\n",
    "print(tokenized_text[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c699b5e",
   "metadata": {},
   "source": [
    "## Pratique: Amelioration de notre correcteur orthographique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b93cfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scence', 'conaissance', 'téorie', 'statistiqe', 'stokage', 'dicipline', 'come']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = open(\"dictionnaire.txt\",\"r\",encoding = 'utf-8').read()\n",
    "text_string = open(\"texte.txt\",'r',encoding=\"utf-8\").read()\n",
    "def clean_text(text_string,special_character,remplacement_string):\n",
    "    cleaned_text = text_string\n",
    "    for string in special_character:\n",
    "        cleaned_text = cleaned_text.replace(string,remplacement_string)\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return (cleaned_text)\n",
    "\n",
    "\n",
    "special_caracter=[',','.',\"'\",'\\n']\n",
    "remplacement =\"\"\n",
    "def tokenize (text_string,special_character,remplacement_string, clean = False ):\n",
    "    cleaned_text= text_string\n",
    "     \n",
    "    if clean:\n",
    "        cleaned_text= clean_text(text_string,special_caracter,remplacement)\n",
    "    text_tokens = cleaned_text.split(\" \")\n",
    "    return (text_tokens)\n",
    "\n",
    "def spell_check(vocabulary_file,text_file,special_characters,remplacement_string):\n",
    "    \n",
    "    special_characters=[',','.',\"'\",'\\n']\n",
    "    remplacement_string =\"\"\n",
    "    misspelled_words=[]\n",
    "    vocabulary = open(vocabulary_file,'r',encoding='utf-8').read()\n",
    "    text = open(text_file,'r',encoding='utf-8').read()\n",
    "    tokenize_vocabulary = tokenize(vocabulary,special_characters,remplacement_string)\n",
    "    tokenize_text= tokenize(text,special_characters,remplacement_string,True)\n",
    "    for test in tokenize_text:\n",
    "        if test not in tokenize_vocabulary and test != \"\" :\n",
    "            misspelled_words.append(test)\n",
    "    return (misspelled_words)\n",
    "special_characters=[',','.',\"'\",'\\n']\n",
    "remplacement_string =\"\"\n",
    "final_missepelled_words = spell_check('dictionnaire.txt','texte.txt',special_characters,remplacement_string)\n",
    "print(final_missepelled_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711a1309",
   "metadata": {},
   "source": [
    "## Types d'erreus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eceb338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on distingue les erreurs de syntaxe et les erreurs , les indemptation d'erreurs,les runtime errors(quand le programme est en cours d'execution et il rencontre un probleme ) , on a les indexerrors si peu etre tu veux atteindre le 7ieme element d'une liste hors que la liste n'en contient que moins de 7 element , attributeError c'est quand tu veux faire une operation sans au prealable attribué certains elements ou sans passser sans certaines actions necessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2021a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
